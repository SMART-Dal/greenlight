["tensorflow.compat.v1.keras.layers.DenseFeatures()", "tensorflow.keras.layers.Concatenate()()", "tensorflow.keras.Model()", "tensorflow.compat.v1.feature_column.categorical_column_with_identity()", "tensorflow.compat.v1.feature_column.indicator_column()", "tensorflow.keras.layers.CategoryEncoding()", "tensorflow.compat.v1.feature_column.numeric_column()", "tensorflow.keras.layers.Normalization()", "tensorflow.compat.v1.feature_column.bucketized_column()", "tensorflow.keras.layers.Discretization()", "tensorflow.compat.v1.feature_column.categorical_column_with_vocabulary_list()", "tensorflow.keras.layers.StringLookup()", "tensorflow.compat.v1.feature_column.embedding_column()", "tensorflow.keras.layers.Embedding()", "tensorflow.constant()", "tensorflow.compat.v1.feature_column.weighted_categorical_column()", "tensorflow.sparse.to_dense()", "tensorflow.keras.layers.Dense()", "tensorflow.compat.v1.estimator.DNNClassifier()", "tensorflow.keras.layers.CategoryEncoding(one_hot_dims, output_mode='one_hot')()", "tensorflow.keras.layers.StringLookup(vocabulary=vocab)()", "tensorflow.keras.layers.Normalization(axis=None, mean=weight_mean, variance=weight_variance)()", "tensorflow.data.Dataset.from_tensor_slices((features, labels)).batch()", "tensorflow.data.Dataset.from_tensor_slices((features, labels)).batch.map()", "tensorflow.keras.layers.Dense(1)()", "tensorflow.keras.Model.compile()", "tensorflow.data.Dataset.from_tensor_slices(predict_features).batch()", "tensorflow.keras.Model.predict()", "tensorflow.keras.Model.save()", "tensorflow.keras.models.load_model()", "tensorflow.keras.models.load_model.predict()"]